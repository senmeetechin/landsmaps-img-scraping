{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a27c749",
   "metadata": {},
   "source": [
    "# Image web scraping model for Bangkok üèõ\n",
    "\n",
    "The model for scraping land information and red parcel boundary point of interest land from https://landsmaps.dol.go.th/\n",
    "\n",
    "üö® **Feature requirement:**\n",
    "- deed_no_ref\n",
    "- province\n",
    "- district\n",
    "- ltt\n",
    "- lgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784bdd3",
   "metadata": {},
   "source": [
    "## üìù Setting all dataset and file path here\n",
    "For quick use, you can set functions, dataframes, image paths, etc. in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ea694",
   "metadata": {},
   "source": [
    "#### üìù Dataframe path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95a6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dataframe\n",
    "input_df_path = 'mockup_data.csv'\n",
    "# Output dataframe\n",
    "output_df_path = 'mockup_result.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd1fe7",
   "metadata": {},
   "source": [
    "#### üìù Set column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6656fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deed_col_name = \"deed_no_ref\"\n",
    "prov_col_name = \"province\"\n",
    "dist_col_name = \"district\"\n",
    "ltt_col_name = \"ltt\"\n",
    "lgt_col_name = \"lgt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f50130",
   "metadata": {},
   "source": [
    "#### üìù Result image directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e75aa46",
   "metadata": {},
   "source": [
    "üö® Don't forget to create these folder. This code doesn't create by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de91cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path for collecting website capture image\n",
    "capture_dir = \"scraping_image/capture/\"\n",
    "\n",
    "# Folder path for collecting website capture image with detecting point (for check accuracy)\n",
    "preview_dir = \"missing_bkk_scrp_img/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5662d4",
   "metadata": {},
   "source": [
    "**Function mode and flag üè≥**\n",
    "- **nearby_district_mode**: Use function for changing to nearby district and correct nearest district (True/False)\n",
    "- **collect_shape_mode**: Use function for collecting land shape points (True/False)\n",
    "- **capture_img_flg** : If using collect shape, do you want to save website's land image to capture_dir (True/False)\n",
    "- **preview_img_flg** : If using collect shape, do you want to save website's land image with detecting point (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5a9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_district_mode = True\n",
    "collect_shape_mode = True  \n",
    "capture_img_flg = False\n",
    "preview_img_flg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089598e",
   "metadata": {},
   "source": [
    "#### üìù Driver path\n",
    "\n",
    "Download chrome driver >> https://chromedriver.chromium.org/downloads (Please check your version of chrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58328ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set work dir to chrome driver path\n",
    "# ~/chromedriver.exe for Windows\n",
    "# ~/chromedriver     for MacOS\n",
    "driver_path = '/Users/senmeetechin/Desktop/00Last code/selenium driver/Mac_x64/chrome108/chromedriver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a23a62",
   "metadata": {},
   "source": [
    "#### üìù Move up pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca4ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From experiment, we move the red pin for 148 px to set it to the center of canvas\n",
    "move_px = 148"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04a376",
   "metadata": {},
   "source": [
    "## 1. INPUT DATA\n",
    "üö® Choose interest dataframe which contain **province**, **ltt**, **lgt**, **district** and **deed_no_ref**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44117e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deed_no_ref</th>\n",
       "      <th>ltt</th>\n",
       "      <th>lgt</th>\n",
       "      <th>province</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61849</td>\n",
       "      <td>13.665516</td>\n",
       "      <td>100.499072</td>\n",
       "      <td>‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£</td>\n",
       "      <td>‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ö‡∏π‡∏£‡∏ì‡∏∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18645</td>\n",
       "      <td>13.844767</td>\n",
       "      <td>100.537520</td>\n",
       "      <td>‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£</td>\n",
       "      <td>‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏∞‡∏ö‡∏±‡∏á</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deed_no_ref        ltt         lgt       province     district\n",
       "0        61849  13.665516  100.499072  ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£  ‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ö‡∏π‡∏£‡∏ì‡∏∞\n",
       "1        18645  13.844767  100.537520  ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£    ‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏∞‡∏ö‡∏±‡∏á"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_loc = pd.read_csv(input_df_path)\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1096a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deed_no_ref</th>\n",
       "      <th>ltt</th>\n",
       "      <th>lgt</th>\n",
       "      <th>province</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [deed_no_ref, ltt, lgt, province, district]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle ‡∏™‡∏≤‡∏ò‡∏£\n",
    "df_loc = df_loc.replace('‡∏™‡∏≤‡∏ò‡∏£', '‡∏™‡∏≤‡∏ó‡∏£')\n",
    "df_loc[df_loc.district=='‡∏™‡∏≤‡∏ò‡∏£']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96289a48",
   "metadata": {},
   "source": [
    "# 2. Web Scaraping\n",
    "For this notebook, I use selenium for webscraping and using chrome as the main browser.\n",
    "\n",
    "Download chrome driver >> https://chromedriver.chromium.org/downloads (Please check your version of chrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51d36d",
   "metadata": {},
   "source": [
    "### 2.1 District converter for web scraping\n",
    "using **thai_loc.json**, and **bkk_loc.json** that I attached with this jupyter notebook or if it got some problem, you can create it by yourself from **df_preparation.ipynb**\n",
    "\n",
    "- **thai_loc.json:** All district converter of all Thai province (Don't support changing to nearby district)\n",
    "- **bkk_loc.json:** All district converter of Bangkok (Support changing to nearby district in bangkok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebbb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# district_converter is for converting district name to web-text name\n",
    "converter = 'bkk_loc.json' # thai_lco or bkk_loc\n",
    "\n",
    "with open(converter, 'r', encoding='utf-8') as json_file:\n",
    "    district_converter = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8d6ea",
   "metadata": {},
   "source": [
    "### 2.2 Open webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e84c2",
   "metadata": {},
   "source": [
    "#### Open webdriver and access website\n",
    "### üö® Please wait until the webdriver is already!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85feb7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/senmeetechin/opt/anaconda3/envs/geo_env/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Open webdriver \n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=1066,792\") # The window size affect to move_px!\n",
    "driver = webdriver.Chrome(driver_path, options=options)\n",
    "\n",
    "# Access website\n",
    "driver.get('https://landsmaps.dol.go.th/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2f9e7",
   "metadata": {},
   "source": [
    "#### Reload and Close pop-up that occur when access website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881498e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n",
    "def reload():\n",
    "    driver.refresh()\n",
    "    # WEB UPDATE: DON'T HAVE POP UP ANYMORE\n",
    "    try:\n",
    "        # wait until close pop-up is clickable\n",
    "        wait = WebDriverWait(driver, 4)\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"modal_news\"]/div/div/div[1]/button'))).click()\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    # change map layer to OpenStreetMap\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"layer\"]').click()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"OpenStreetMap\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f4d705",
   "metadata": {},
   "source": [
    "### 2.3 Access to interest location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a3be7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill province, district, and deed_no_ref to website text-field\n",
    "def access_loc(province, district_web, deed_no_ref):    \n",
    "    # Set province in website\n",
    "    province_select = Select(driver.find_element(By.XPATH, '//*[@id=\"cbprovince\"]'))\n",
    "    province_select.select_by_visible_text(province)\n",
    "    \n",
    "    # Set district in website\n",
    "    district_select = Select(driver.find_element(By.XPATH, '//*[@id=\"cbamphur\"]'))\n",
    "    district_select.select_by_visible_text(district_web)\n",
    "    \n",
    "    # Set deed_no_ref in website\n",
    "    deedno_select = driver.find_element(By.XPATH, '//*[@id=\"txtparcelno\"]')\n",
    "    deedno_select.clear()\n",
    "    deedno_select.send_keys(str(deed_no_ref))\n",
    "\n",
    "    # click find button\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"btnSearch\"]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12b954",
   "metadata": {},
   "source": [
    "#### Move canvas by cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec54cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "import time\n",
    "\n",
    "# set pin to center of canvas\n",
    "def move_up(px):\n",
    "    canvas = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[1]/div[1]/div/canvas')\n",
    "    action = ActionChains(driver)\n",
    "    action.click_and_hold(canvas)\\\n",
    "        .move_to_element_with_offset(canvas, 0, -1*px)\\\n",
    "        .pause(1)\\\n",
    "        .release()\\\n",
    "        .perform()\n",
    "    \n",
    "# Zoom in/out (delY<0: zoom in, delY>0: zoom out)\n",
    "def zoom_in(delY):\n",
    "    canvas = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[1]/div[1]/div/canvas')\n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element_with_offset(canvas, 0, 0)\n",
    "    canvas_origin = ScrollOrigin.from_element(canvas, 0, 0)\n",
    "    action.scroll_from_origin(canvas_origin, 0, delY).perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee02b1e",
   "metadata": {},
   "source": [
    "### 2.4 Get info by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f3d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_info(df_loc):\n",
    "    \n",
    "    df_out = df_loc.copy()\n",
    "    try: \n",
    "        # Click office button -> If don't have, the location doesn't access\n",
    "        wait = WebDriverWait(driver, 4)\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"accordion\"]/div/div[3]'))).click()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # collect dealing file number - ‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏£‡∏ß‡∏à\n",
    "        try:\n",
    "            deal_no = int(driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[2]/div[2]').text)\n",
    "            df_out['deal_no'] = deal_no\n",
    "        except:\n",
    "            df_out['deal_no'] = None\n",
    "\n",
    "        # collect land number - ‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô\n",
    "        try:\n",
    "            land_no = int(driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[3]/div[2]').text)\n",
    "            df_out['land_no'] = land_no\n",
    "        except:\n",
    "            df_out['land_no'] = None\n",
    "\n",
    "        # collect sheet - ‡∏£‡∏∞‡∏ß‡∏≤‡∏á\n",
    "        try:\n",
    "            sheet = driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[4]/div[2]').text\n",
    "            df_out['sheet'] = sheet\n",
    "        except:\n",
    "            df_out['sheet'] = None\n",
    "\n",
    "        # collect area - ‡πÑ‡∏£‡πà, ‡∏á‡∏≤‡∏ô, ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ß‡∏≤\n",
    "        try:\n",
    "            area = driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[8]/div[2]').text\n",
    "            rai = float(area.split(' ')[0].replace(',',''))\n",
    "            ngan = float(area.split(' ')[2].replace(',',''))\n",
    "            talangwa = float(area.split(' ')[4].replace(',',''))\n",
    "            df_out['area'] = area\n",
    "            df_out['rai'] = rai\n",
    "            df_out['ngan'] = ngan\n",
    "            df_out['talangwa'] = talangwa\n",
    "        except:\n",
    "            df_out['area'] = None\n",
    "            df_out['rai'] = None\n",
    "            df_out['ngan'] = None\n",
    "            df_out['talangwa'] = None\n",
    "\n",
    "        # collect estimation price - ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô\n",
    "        try:\n",
    "            est_price = driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[9]/div[2]').text\n",
    "            est_price = float(est_price.split(' ')[0].replace(',',''))\n",
    "            df_out['est_price'] = est_price\n",
    "        except:\n",
    "            df_out['est_price'] = None\n",
    "\n",
    "        # collect parcel coordinates - ‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á\n",
    "        try:\n",
    "            parcel_coor = driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[10]/div[2]/a').text\n",
    "            parcel_ltt = float(parcel_coor.split(',')[0])\n",
    "            parcel_lgt = float(parcel_coor.split(',')[1])\n",
    "            df_out['parcel_ltt'] = parcel_ltt\n",
    "            df_out['parcel_lgt'] = parcel_lgt\n",
    "        except:\n",
    "            df_out['parcel_ltt'] = None\n",
    "            df_out['parcel_lgt'] = None\n",
    "\n",
    "        # collect land office - ‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô\n",
    "        try:\n",
    "            land_office = driver.find_element(By.XPATH, '//*[@id=\"demo2\"]/div[1]/div[2]').text\n",
    "            df_out['land_office'] = land_office\n",
    "        except:\n",
    "            df_out['land_office'] = None\n",
    "\n",
    "        # collect office coordinates - ‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô\n",
    "        try:\n",
    "            office_coor = driver.find_element(By.XPATH, '//*[@id=\"demo2\"]/div[7]/div[2]').text\n",
    "            office_ltt = float(office_coor.split(',')[0])\n",
    "            office_lgt = float(office_coor.split(',')[1])\n",
    "            df_out['office_ltt'] = office_ltt\n",
    "            df_out['office_lgt'] = office_lgt \n",
    "        except:\n",
    "            df_out['office_ltt'] = None\n",
    "            df_out['office_lgt'] = None\n",
    "\n",
    "        # Close office button\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"accordion\"]/div/div[3]').click()\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    except:\n",
    "#         print(\"ERROR: can't find contour of POI\")\n",
    "        df_out['error'] = \"can't find contour of POI\"\n",
    " \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "228c7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent the driver click any link, this function will close the other tab\n",
    "def close_multiple_tab():\n",
    "    # If driver has multiple tab in browser\n",
    "    while len(driver.window_handles)>1:\n",
    "\n",
    "        # Switch to the new window and close it\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        driver.close()\n",
    "\n",
    "        # Switching to old tab\n",
    "        driver.switch_to.window(driver.window_handles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21012341",
   "metadata": {},
   "source": [
    "### 2.5 Image capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc387f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide website element\n",
    "def hide_menu():\n",
    "    js_script = '''\n",
    "    document.querySelector(\".wrapper\").style.visibility = \"hidden\";\n",
    "    document.querySelector(\".navbar\").style.visibility = \"hidden\";\n",
    "    document.querySelector(\".myDiv\").style.visibility = \"hidden\";\n",
    "    document.querySelector(\".cesium-viewer-toolbar\").style.visibility = \"hidden\";\n",
    "    document.querySelector(\"#layer\").style.visibility = \"hidden\";\n",
    "    document.querySelector(\"#menu\").style.visibility = \"hidden\";\n",
    "\n",
    "    '''\n",
    "    driver.execute_script(js_script)\n",
    "    \n",
    "# show website element\n",
    "def show_menu():\n",
    "    js_script = '''\n",
    "    document.querySelector(\".wrapper\").style.visibility = \"visible\";\n",
    "    document.querySelector(\".navbar\").style.visibility = \"visible\";\n",
    "    document.querySelector(\".myDiv\").style.visibility = \"visible\";\n",
    "    document.querySelector(\".cesium-viewer-toolbar\").style.visibility = \"visible\";\n",
    "    document.querySelector(\"#layer\").style.visibility = \"visible\";\n",
    "    document.querySelector(\"#menu\").style.visibility = \"visible\";\n",
    "\n",
    "    '''\n",
    "    driver.execute_script(js_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd97dc",
   "metadata": {},
   "source": [
    "#### Capture canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6724647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def get_canvas_info():\n",
    "    canvas = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[1]/div[1]/div/canvas')\n",
    "    canvas_loc = canvas.location\n",
    "    canvas_size = canvas.size\n",
    "    return canvas_loc, canvas_size\n",
    "\n",
    "def capture_img(canvas_loc, canvas_size):\n",
    "    # hide menu for capturing\n",
    "    hide_menu()\n",
    "\n",
    "    # saves screenshot of entire page\n",
    "    canvas = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[1]/div[1]/div/canvas')\n",
    "    png = canvas.screenshot_as_png\n",
    "\n",
    "    # uses PIL library to open image in memory\n",
    "    capture = Image.open(BytesIO(png))\n",
    "\n",
    "    # crop only canvas\n",
    "    left = canvas_loc['x']\n",
    "    top = canvas_loc['y']\n",
    "    right = canvas_loc['x'] + canvas_size['width']\n",
    "    bottom = canvas_loc['y'] + canvas_size['height']\n",
    "\n",
    "    capture = capture.crop((left, top, right, bottom)) # defines crop points\n",
    "    show_menu()\n",
    "    # set capture size (handle in case of zoom-website)\n",
    "    capture_slice = np.array(capture)[:canvas_size['height'], :canvas_size['width'], :]\n",
    "    return capture_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451613e",
   "metadata": {},
   "source": [
    "### 2.6 Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5255f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f52208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only red color from image\n",
    "def filter_red(img):\n",
    "    im = img.copy()\n",
    "    red_im = im[:,:,0]\n",
    "    green_im = im[:,:,1]\n",
    "    blue_im = im[:,:,2]\n",
    "    red_filtered = (red_im > 200) & (green_im < 200) & (blue_im < 200)\n",
    "    \n",
    "    # Closing morphology\n",
    "    img = np.array(red_filtered * 255, dtype = np.uint8)\n",
    "    shape = red_filtered.shape\n",
    "    return img, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "373d4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the contour is bound the interesting land parcel\n",
    "def check_loc(contours, loc_idx, shape):\n",
    "    # fill contours\n",
    "    contour_loc = contours[loc_idx]\n",
    "    fill_contour = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    cv2.fillPoly(fill_contour, [contour_loc], 255)\n",
    "    # check the pin location is filled or not\n",
    "    if(fill_contour[shape[0]//2, shape[1]//2] == 255):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76255b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all edge of image, and get contour of interesting location\n",
    "def get_map_line(red_filtered):    \n",
    "    img = red_filtered\n",
    "\n",
    "    # apply morphology close\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "#     thresh = cv2.erode(img, kernel, iterations = 1)\n",
    "    thresh = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # get contours and filter on area\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_cp = contours\n",
    "\n",
    "    # get location contours from hierarchy [Next, Previous, First_Child, Parent]\n",
    "    loc_idx = -1\n",
    "    contours_del = []\n",
    "    for hier_idx, pin in enumerate(hierarchy[0]):\n",
    "        if pin[0] == -1 and pin[1] == -1 and pin[2] == -1:\n",
    "            # Case: Full pin\n",
    "            pin_idx = pin[3]\n",
    "            pin_parent_idx = hierarchy[0][pin_idx][3]\n",
    "            # check correctness\n",
    "            if check_loc(contours, pin_parent_idx, img.shape):\n",
    "                contours_del.append(pin_idx)\n",
    "                contours_del.append(hier_idx)\n",
    "                loc_idx = pin_parent_idx\n",
    "#             # Case: Half pin\n",
    "#             loc_idx = pin[3]\n",
    "#             contours_del.append(hier_idx)\n",
    "    # delete pin\n",
    "    pin_del = [idx for idx in set(contours_del)]\n",
    "    contours_cp = np.delete(contours_cp, pin_del)\n",
    "    # draw all contours\n",
    "    map_line = np.zeros(shape=(red_filtered.shape), dtype=np.uint8)\n",
    "    for c in contours_cp:\n",
    "        cv2.drawContours(map_line, [c], -1, 255, 2)\n",
    "    return loc_idx, contours, hierarchy, map_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ec9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contour of interest location and points of contour\n",
    "def get_interest_loc(contours, loc_idx, shape):\n",
    "    # fill location contours\n",
    "    contour_loc = contours[loc_idx]\n",
    "    contour_line = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    cv2.drawContours(contour_line, [contour_loc], -1, 255, 2)\n",
    "\n",
    "    # dilation for increasing point size\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    contour_point = cv2.dilate(contour_line, kernel, iterations=1)\n",
    "    \n",
    "    # Find center of contour\n",
    "    M = cv2.moments(contour_loc)\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        center = [cy, cx]\n",
    "    else:\n",
    "        center = None\n",
    "    return contour_loc, contour_line, contour_point, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09c1e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect corner point of interesting shape from contour_line\n",
    "def corner_detection(contour_line, contour_loc, shape):\n",
    "    # Find corner point\n",
    "    dst = cv2.cornerHarris(contour_line,2,3,0.04)\n",
    "    cor_point = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    cor_point[dst>0.08*dst.max()] = 255\n",
    "    \n",
    "    # Dilation -> increase size of point\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    large_cor_point = cv2.dilate(cor_point, kernel, iterations=1)\n",
    "    \n",
    "    # draw contour point\n",
    "    contour_point = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    for point in contour_loc:\n",
    "        x, y = point[0]\n",
    "        contour_point[y][x] = 255\n",
    "    \n",
    "    # Find the point that intersect between contour point and corner point\n",
    "    corner_points = np.bitwise_and(large_cor_point, contour_point)\n",
    "    \n",
    "    # Send non-zero position in array as output\n",
    "    corner_points1 = np.transpose(np.nonzero(np.copy(corner_points))).tolist()\n",
    "    return corner_points1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d442804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection intersection point from all contour of image\n",
    "def intersec_detection(map_line, contour_loc, shape):\n",
    "    # thining all contour of image\n",
    "    skeleton = cv2.ximgproc.thinning(map_line, None, 1)\n",
    "    _, binaryImage = cv2.threshold(skeleton, 128, 10, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "    # Set the intersections kernel:\n",
    "    h = np.array([[1, 1, 1],\n",
    "                  [1, 10, 1],\n",
    "                  [1, 1, 1]])\n",
    "\n",
    "    # Convolve the image with the kernel\n",
    "    imgFiltered = cv2.filter2D(binaryImage, -1, h)\n",
    "\n",
    "    # Prepare the final mask of points\n",
    "    (height, width) = binaryImage.shape\n",
    "    pointsMask = np.zeros((height, width, 1), np.uint8)\n",
    "\n",
    "    # Perform convolution and create points mask\n",
    "    thresh = 130\n",
    "    # Locate the threshold in the filtered image\n",
    "    pointsMask = np.where(imgFiltered == thresh, 255, 0)\n",
    "\n",
    "    # Convert and shape the image to a uint8 height x width x channels\n",
    "    pointsMask = pointsMask.astype(np.uint8)\n",
    "\n",
    "    # dilation for increasing point size\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    intersec_point = cv2.dilate(pointsMask, kernel, iterations=2)\n",
    "\n",
    "    # draw contour points\n",
    "    contour_point = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    for point in contour_loc:\n",
    "        x, y = point[0]\n",
    "        contour_point[y][x] = 255\n",
    "    \n",
    "    # Find the point that intersect between contour points and intersection points\n",
    "    result = np.bitwise_and(contour_point, intersec_point)\n",
    "    \n",
    "    # Send non-zero position in array as output\n",
    "    corner_points2 = np.transpose(np.nonzero(np.copy(result))).tolist()\n",
    "    return corner_points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd65e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge corner points and intersection points together and sort in the order of contour points\n",
    "def merge_point(corner_points1, corner_points2, contour_loc, shape, center):\n",
    "    # merge corner point and intersection point\n",
    "    corner_points = corner_points1 + corner_points2\n",
    "    \n",
    "    # get contour point\n",
    "    contour_point = []\n",
    "    for point in contour_loc:\n",
    "        x, y = point[0]\n",
    "        contour_point.append([y,x])\n",
    "    \n",
    "    # sort merge list by contour points\n",
    "    corner_points.sort(key=lambda point: contour_point.index(point))\n",
    "\n",
    "    # combine closed point together\n",
    "    count = 1\n",
    "    while(count):\n",
    "        count = 0\n",
    "        for idx, point in enumerate(corner_points):\n",
    "            a, b = point\n",
    "            match = 0\n",
    "            dist = 7\n",
    "            for other_point in corner_points[idx:]:\n",
    "                if other_point == point:\n",
    "                    continue\n",
    "                c, d = other_point\n",
    "                if abs(c-a) < dist and abs(d-b) < dist:\n",
    "                    match = 1\n",
    "                    corner_points[idx] = [(c+a)//2, (d+b)//2]\n",
    "                    corner_points.remove(other_point)\n",
    "                    count = count + 1\n",
    "            \n",
    "    return corner_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9843827",
   "metadata": {},
   "source": [
    "### 2.7 Get ltt, lgt from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef8f472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unable mouse interact when pointing on canvas in website\n",
    "def unable_mouse_interact():\n",
    "    js_script = '''\n",
    "    document.querySelector(\"#cesiumContainer > div.twipsy.right\").style['pointer-events'] = \"none\";\n",
    "    '''\n",
    "    driver.execute_script(js_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0da78996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of ltt, lgt on canvas from the result of corner points\n",
    "def get_ltt_lgt(corner_points):\n",
    "    # open toolbox\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"imageButton\"]').click()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"marker\"]'))).click()\n",
    "    hide_menu()\n",
    "    unable_mouse_interact()\n",
    "\n",
    "    location = []\n",
    "    # point the corner location\n",
    "    for point in corner_points:\n",
    "        x, y = point\n",
    "        canvas = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[1]/div[1]/div/canvas')\n",
    "        action = ActionChains(driver)\n",
    "        action.move_to_element_with_offset(canvas, y-canvas.rect['width']//2, x-canvas.rect['height']//2).perform()\n",
    "#         action.move_to_element_with_offset(canvas, y, x).perform()\n",
    "        loc = driver.find_element(By.XPATH, '//*[@id=\"cesiumContainer\"]/div[2]/div[2]').text\n",
    "        location.append(loc)\n",
    "\n",
    "    # close toolbox\n",
    "    show_menu()\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"clear\"]'))).click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"imageButton\"]').click()\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb64826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw image and result of model in selection path\n",
    "def preview_img(corner_points, capture, shape, deed_no_ref, district, capture_dir, preview_dir, capture_img_flg, preview_img_flg):\n",
    "    # Dilation -> Increase corner point size\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    test = np.zeros(shape=(shape), dtype=np.uint8)\n",
    "    for point in corner_points:\n",
    "        x, y = point\n",
    "        test[x][y] = 255\n",
    "    test = cv2.dilate(test, kernel, iterations=2)\n",
    "    # get point as list of pixel\n",
    "    test = np.transpose(np.nonzero(np.copy(test))).tolist()\n",
    "\n",
    "    # set capture image as background\n",
    "    bg = np.array(capture)\n",
    "    raw = Image.fromarray(bg)\n",
    "    # save capture image to selection path\n",
    "    if capture_img_flg:\n",
    "        raw.save(preview_dir+str(deed_no_ref)+'_'+str(district)+'_capture.png')\n",
    "    \n",
    "    # plot point on image\n",
    "    for point in test:\n",
    "        x, y = point\n",
    "        bg[x][y] = np.array([0,0,255,255])\n",
    "    \n",
    "    # save capture image with the result point to selection path\n",
    "    preview = Image.fromarray(bg)\n",
    "    if preview_img_flg:\n",
    "        preview.save(preview_dir+str(deed_no_ref)+'_'+str(district)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec8c94",
   "metadata": {},
   "source": [
    "## 3.COMBINE ALL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ebb7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ltt_lgt(df, max_diff):\n",
    "    if 'parcel_ltt' not in df.keys():\n",
    "        return False\n",
    "    \n",
    "    ltt = df['ltt']\n",
    "    lgt = df['lgt']\n",
    "    parcel_ltt = df['parcel_ltt']\n",
    "    parcel_lgt = df['parcel_lgt']\n",
    "    diff_ltt = abs(ltt - parcel_ltt)\n",
    "    diff_lgt = abs(lgt - parcel_lgt)\n",
    "    if diff_ltt <= 0.0001 and diff_lgt <= 0.0001:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8d75e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping red parcel\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "def red_deed_scraping(deed_no_ref, \n",
    "                      province, \n",
    "                      district,\n",
    "                      ltt,\n",
    "                      lgt,\n",
    "                      nearby_district_mode=True,\n",
    "                      max_diff=1e-4,\n",
    "                      collect_shape_mode=True, \n",
    "                      capture_img_flg=False,\n",
    "                      preview_img_flg=False):\n",
    "    # Set website-zoom as 100%\n",
    "    canvas_loc, canvas_size = get_canvas_info()\n",
    "    driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "    \n",
    "    # set result of Series\n",
    "    df = {}\n",
    "    df['deed_no_ref'] = deed_no_ref\n",
    "    df['province'] = province\n",
    "    df['district'] = district\n",
    "    df['ltt'] = ltt\n",
    "    df['lgt'] = lgt\n",
    "    df['ltt_poly'] = None\n",
    "    df['lgt_poly'] = None\n",
    "    df['error'] = None\n",
    "    \n",
    "    # correct all nearby district\n",
    "    district_list = district_converter[province][district]\n",
    "    ltt_lgt_checker = False\n",
    "    \n",
    "    # loop until it can access location (In nearby district mode)\n",
    "    count_found = 0\n",
    "    parcel_list = []\n",
    "    parcel_list_diff = []\n",
    "    dist_list = []\n",
    "    mini_distance = np.Inf\n",
    "    for dist_i, district_web in enumerate(district_list):\n",
    "        try:\n",
    "            # refresh website\n",
    "            reload()\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            # CASE: Can't click openstreetmap layer\n",
    "            print(\"ERROR: Problem with reload\")\n",
    "            df['error'] = \"problem with reload\"\n",
    "            \n",
    "        try:\n",
    "            # access location in website\n",
    "            access_loc(province, district_web, deed_no_ref)\n",
    "            time.sleep(3)\n",
    "            df = get_loc_info(df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            # close info box\n",
    "            wait = WebDriverWait(driver, 5)\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"accordion\"]/div/div[12]/button[3]'))).click()\n",
    "            time.sleep(1)\n",
    "\n",
    "            # prevent driver click any link\n",
    "            close_multiple_tab()\n",
    "\n",
    "            # check ltt and lgt of parcel is correct or not\n",
    "            if check_ltt_lgt(df, max_diff):\n",
    "                ltt_lgt_checker = True\n",
    "                df['web_district'] = district_web.split('-')[-1]\n",
    "                break\n",
    "            else:\n",
    "                if dist_i==0:\n",
    "                    df['found1st_wrong'] = 1\n",
    "                count_found = count_found+1\n",
    "                parcel_list.append((df['parcel_ltt'], df['parcel_lgt']))\n",
    "                diff_ltt = df['parcel_ltt']-df['ltt']\n",
    "                diff_lgt = df['parcel_lgt']-df['lgt']\n",
    "                parcel_list_diff.append((diff_ltt, diff_lgt))\n",
    "                dist_list.append(district_web)\n",
    "                df['found_land'] = count_found\n",
    "                df['parcel_found'] = parcel_list\n",
    "                df['parcel_diff_found'] = parcel_list_diff\n",
    "                df['district_found'] = dist_list\n",
    "\n",
    "                # find minimal distance\n",
    "                distance = sqrt(diff_ltt**2 + diff_lgt**2)\n",
    "                if distance < mini_distance:\n",
    "                    mini_distance = distance\n",
    "                    df['mini_distance_district'] = district_web\n",
    "                    df['mini_distance_index'] = len(parcel_list_diff)-1\n",
    "        except:\n",
    "            None \n",
    "        \n",
    "        # Break if not nearby district mode for getting only first district\n",
    "        if not nearby_district_mode:\n",
    "            break\n",
    "    \n",
    "    if not ltt_lgt_checker:\n",
    "        if mini_distance<np.Inf:\n",
    "            access_loc(province, df['mini_distance_district'], deed_no_ref)\n",
    "            df['web_district'] = df['mini_distance_district']\n",
    "            time.sleep(3)\n",
    "            df = get_loc_info(df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            # close info box\n",
    "            wait = WebDriverWait(driver, 5)\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"accordion\"]/div/div[12]/button[3]'))).click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # prevent driver click any link\n",
    "            close_multiple_tab()\n",
    "        else:\n",
    "            # CASE: Can't access interesting location (Wrong data or Website doesn't have location data)\n",
    "            print(\"ERROR: can't access POI data\")\n",
    "            df['error'] = \"can't access POI data\"\n",
    "            return df\n",
    "         \n",
    "    # prevent driver click any link\n",
    "    close_multiple_tab()\n",
    "\n",
    "    try:\n",
    "        # Set pin to the center and zoom to location\n",
    "        move_up(move_px) # window 146, mac 169\n",
    "        for i in range(4):\n",
    "            zoom_in(-400)\n",
    "        time.sleep(2)\n",
    "\n",
    "    except:\n",
    "        # CASE: Found problem while zooming (Selenium initial problem)\n",
    "        print(\"ERROR: problem with zoom in\")\n",
    "        df['error'] = \"problem with zoom in\"\n",
    "        return df\n",
    "    \n",
    "    # Set website-zoom to 50% (for smaller pin size)\n",
    "    driver.execute_script(\"document.body.style.zoom='50%'\")\n",
    "    # Capture canvas\n",
    "    capture = capture_img(canvas_loc, canvas_size)\n",
    "    # Filter red color from image\n",
    "    red_filtered, shape = filter_red(capture)\n",
    "    \n",
    "    try:\n",
    "        # Get contour of interested location\n",
    "        loc_idx, contours, hierarchy, map_line = get_map_line(red_filtered)\n",
    "\n",
    "        # Zoom out until interested location is closed area\n",
    "        count = 0\n",
    "        while(loc_idx < 0 and count < 6):\n",
    "            zoom_in(200)\n",
    "            time.sleep(2)\n",
    "            # Set webiste-zoom to 50% (For smaller pin size, but thinner red line)\n",
    "            driver.execute_script(\"document.body.style.zoom='50%'\")\n",
    "            capture = capture_img(canvas_loc, canvas_size)\n",
    "            red_filtered, shape = filter_red(capture)\n",
    "            try:\n",
    "                loc_idx, contours, hierarchy, map_line = get_map_line(red_filtered)\n",
    "                if(not check_loc(contours, loc_idx, shape)):\n",
    "                    loc_idx = -1\n",
    "            except:\n",
    "                loc_idx = -1\n",
    "            # Set website-zoom to 100% (For bigger red line, but bigger pin size)\n",
    "            if loc_idx == -1:\n",
    "                driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "                capture = capture_img(canvas_loc, canvas_size)\n",
    "                red_filtered, shape = filter_red(capture)\n",
    "                try:\n",
    "                    loc_idx, contours, hierarchy, map_line = get_map_line(red_filtered)\n",
    "                except:\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "            try:\n",
    "                if(not check_loc(contours, loc_idx, shape)):\n",
    "                    loc_idx = -1\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "            except:\n",
    "                count = count + 1\n",
    "                continue\n",
    "                \n",
    "    except:\n",
    "        # CASE: Can't find contour of location in image (too thin red line, pin touch red line, etc.)\n",
    "        print(\"ERROR: can't find contour of POI\")\n",
    "        df['error'] = \"can't find contour of POI\"\n",
    "        return df\n",
    "    \n",
    "    if(count == 6):\n",
    "        # CASE: Can't find contour of location in image after 8 times zoom out (too large location)\n",
    "        print(\"ERROR: can't find contour of POI\")\n",
    "        df['error'] = \"can't find contour of POI\"\n",
    "        return df\n",
    "    else:\n",
    "        # Set website-zoom to 100% for using website tool element\n",
    "        driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "        try:\n",
    "            # Image processing\n",
    "            contour_loc, contour_line, contour_point, center = get_interest_loc(contours, loc_idx, shape)\n",
    "            corner_points1 = corner_detection(contour_line, contour_loc, shape)\n",
    "            corner_points2 = intersec_detection(map_line, contour_loc, shape)\n",
    "            corner_points = merge_point(corner_points1, corner_points2, contour_loc, shape, center)\n",
    "            # Get ltt and lgt from location\n",
    "            location = get_ltt_lgt(corner_points)\n",
    "            # Collect ltt and lgt and save to df Series\n",
    "            ltt_list = []\n",
    "            lgt_list = []\n",
    "            for loc in location:\n",
    "                if loc != '':\n",
    "                    ltt_list.append(float(loc.split(', ')[0]))\n",
    "                    lgt_list.append(float(loc.split(', ')[1]))\n",
    "            df['ltt_poly'] = ltt_list\n",
    "            df['lgt_poly'] = lgt_list\n",
    "            # Save image for checking the result of model\n",
    "            if capture_img_flg or preview_img_flg:\n",
    "                preview_img(corner_points, capture, shape, df['deed_no_ref'], df['district'], capture_dir, preview_dir, capture_img_flg, preview_img_flg)\n",
    "            df['error'] = None\n",
    "            return df\n",
    "        except:\n",
    "            # CASE: Problem with getting ltt and lgt (website tool element problem)\n",
    "            print(\"ERROR: can't get ltt, lgt of POI\")\n",
    "            df['error'] = \"can't get ltt, lgt of POI\"\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd09065",
   "metadata": {},
   "source": [
    "## 4. Apply model to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fda713",
   "metadata": {},
   "source": [
    "### üö® If this cell got an error please reload the web driver site and run this cell again \n",
    "until the first location can access (If the first location work correctly, the next scraping can handle itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7540f78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing [1/2]\n",
      "I'm doing [2/2]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "start = 0\n",
    "df_loc_i = df_loc[start:]\n",
    "length = len(df_loc)\n",
    "\n",
    "data_dict_list = []\n",
    "for i in range(len(df_loc_i)):\n",
    "    print(f\"I'm doing [{i+1+start}/{length}]\")\n",
    "    # get info\n",
    "    deed_no_ref = df_loc_i.iloc[i][deed_col_name]\n",
    "    province = df_loc_i.iloc[i][prov_col_name]\n",
    "    district = df_loc_i.iloc[i][dist_col_name]\n",
    "    ltt = df_loc_i.iloc[i][ltt_col_name]\n",
    "    lgt = df_loc_i.iloc[i][lgt_col_name]\n",
    "    \n",
    "    # scraping\n",
    "    data_out = red_deed_scraping(deed_no_ref, province, district, ltt, lgt, nearby_district_mode, 1e-4, collect_shape_mode, capture_img_flg, preview_img_flg)\n",
    "    # add data to dict list\n",
    "    data_dict_list.append(data_out)\n",
    "    current_df = pd.DataFrame(data_dict_list)\n",
    "    \n",
    "    # save to csv\n",
    "    current_df.to_csv(output_df_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babe898",
   "metadata": {},
   "source": [
    "## 6. Close web driver when finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69f2dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
